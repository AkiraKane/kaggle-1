{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iMatreialist - Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFNW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @alkari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct h5 file from raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import h5py, time, os\n",
    "from PIL import Image\n",
    "\n",
    "size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "def elapsed (elapsed):\n",
    "    hours, rem = divmod(elapsed, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = 'test_images' # '/Users/alkari/Desktop/nasnet/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(images_path)\n",
    "#!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for file in os.listdir('.')[:]:\n",
    "    fname = file.split('.')\n",
    "    if fname[1]=='jpg':\n",
    "        image_id = int(fname[0])\n",
    "        filelist.append(image_id)\n",
    "    else:\n",
    "        print('error '+file)\n",
    "\n",
    "#print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "images = []\n",
    "missing = []\n",
    "for i in range(12801):\n",
    "    \n",
    "    if i in filelist:\n",
    "\n",
    "        image = Image.open(str(i)+'.jpg') \n",
    "        # Ensure right mode\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        # Resize\n",
    "        image = image.resize((size,size), resample=Image.LANCZOS)\n",
    "        image = np.asarray(image)\n",
    "        # preprocess\n",
    "        image = image.astype('float32', copy=False)\n",
    "        image /= 127.5\n",
    "        image -=1        \n",
    "        \n",
    "        # if bad image, skip\n",
    "        if image.shape != (size,size,3):\n",
    "            print(\"Image \"+str(image_id)+\" size: \"+str(image.shape)) \n",
    "\n",
    "    else:\n",
    "        image = np.zeros((224,224,3))\n",
    "        missing.append(i)\n",
    "\n",
    "    # add image to images list\n",
    "    images.append( image )\n",
    "\n",
    "\n",
    "    if not i % 1000:\n",
    "        print(str(i)+' images loaded in {}'.format(elapsed(time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../eval_dataset.h5', 'w') as hf:\n",
    "    hf.create_dataset('test_dataset',\n",
    "                      data=images,\n",
    "                      compression='gzip',\n",
    "                      compression_opts=9,\n",
    "                      chunks=(1000,224,224,3)\n",
    "                     )\n",
    "    hf.create_dataset('missing', data=missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py, time, os\n",
    "\n",
    "model_path = '/Users/alkari/Documents/GoogleDrive/iMaterialist/iMaterialist-model.h5'\n",
    "#trained_weights = '~/Documents/GoogleDrive/nasnet/weights/NASNet-iMaterialist (1).h5'\n",
    "\n",
    "size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('~/Desktop/')\n",
    "os.makedirs('nasnet', exist_ok=True)\n",
    "os.chdir('nasnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp '~/Documents/GoogleDrive/nasnet/weights/NASNet-iMaterialist (1).h5' NASNet-iMaterialist.h5\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.device('/CPU:0'):\n",
    "  print('Loading model takes about 3 minutes...')\n",
    "  model=load_model(model_path)\n",
    "  print('Model loaded. Loading weights...')\n",
    "  model.load_weights('NASNet-iMaterialist.h5')\n",
    "  print('Weights loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_final_testset(filename,max=None):\n",
    "    with h5py.File(filename, 'r') as hf:\n",
    "        test_images = hf['test_dataset'][:max]\n",
    "        #test_images = preprocess_input(test_images)\n",
    "        missing = hf['missing'][:]\n",
    "    return test_images,missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '~/Desktop/nasnet/eval_dataset.h5'\n",
    "x_test_final,missing = load_final_testset(test_file)\n",
    "predictions = model.predict(x_test_final, verbose=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[0].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for files force labeled 0 to 128 and label missing files.\n",
    "arbitrary = 7 # or random!\n",
    "for i in range(predictions.shape[0]):\n",
    "    if predictions[i]==0:\n",
    "        predictions[i]=128\n",
    "        print('Changed image {} from 0 to {}'.format(i,predictions[i]))\n",
    "    if i in missing:\n",
    "        predictions[i]=arbitrary\n",
    "        print('Changed missing image {} prediction to {}'.format(i,predictions[i]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id' : range(len(predictions)), \n",
    "                   'predicted' : predictions})\n",
    "df = df.drop(0) # Drop none existent image[0] prediction\n",
    "if not os.path.isdir('predictions'):\n",
    "    os.mkdir('predictions')\n",
    "filename = 'predictions/tfnw-preds_' + time.strftime('%Y%m%d_%H%M%S_%Z.csv')\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head $filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(predictions.shape[0]-10,predictions.shape[0]):\n",
    "    print(i, predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail $filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
