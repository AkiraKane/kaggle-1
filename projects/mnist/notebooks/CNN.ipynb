{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and assign to X and y\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "y_train = train[\"label\"]\n",
    "\n",
    "# Now normalize the test and train sets\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 42000, test size: 28000\n"
     ]
    }
   ],
   "source": [
    "# What are the sizes of the train and test sets?\n",
    "print('train size: ' + str(len(X_train)) + ', test size: ' + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# So we have 42,000 train images and 28,000 test images\n",
    "# let's go ahead and print one\n",
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182f165208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's now reshape it into a 28 x 28 matrix\n",
    "image = X_train[9]\n",
    "print(image.shape)\n",
    "\n",
    "# Let's plot it now\n",
    "plt.imshow(image.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [7],\n",
       "       [6],\n",
       "       [9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at the labels\n",
    "print(y_train.values.shape)\n",
    "y_train.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the labels are NOT one hot encoded. We need to do that\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train_ohe = enc.fit_transform(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first reset our graph, so our neural network components are all declared within the same graph\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input, X, is 28 x 28 grayscale (1 color channel) images, and\n",
    "# I'll break them up into mini-batches of an unknown size at this\n",
    "# point -- thus the 'None' as the 1st dimension\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "# y_hat, estimates output by the softmax layer\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "# we'll do a variable learning rate\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of channels (aka. kernels or filters) that will be\n",
    "# applied in each convolutional layer\n",
    "c1 = 6 # first convolutional layer\n",
    "c2 = 12 # second convolutional layer\n",
    "c3 = 24 # third convolutional layer\n",
    "\n",
    "# the size of each filter (5 by 5)\n",
    "filter_size = 5\n",
    "\n",
    "# then we'll have one fully connected layer with 200 nodes\n",
    "f1 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to setup the weights and biases associated with each layer.\n",
    "# Note how much smaller the number of parameters is as compared with\n",
    "# a fully connected NN with similar number of layers.\n",
    "\n",
    "# We'll set W1 with positive values from a Gaussian distribution\n",
    "# having standard deviation of 0.1\n",
    "\n",
    "# TODO fully understand this matrix math here\n",
    "W1 = tf.Variable(tf.truncated_normal([filter_size, filter_size, 1, c1], stddev=0.1))\n",
    "B1 = tf.Variable(tf.ones([c1])/10)\n",
    "W2 = tf.Variable(tf.truncated_normal([filter_size, filter_size, c1, c2], stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([c2])/10)\n",
    "W3 = tf.Variable(tf.truncated_normal([filter_size, filter_size, c2, c3], stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([c3])/10)\n",
    "\n",
    "# Now the weights and biases for the fully connected layer. It's\n",
    "# 7 * 7 * 24 by 200 because the activation matrix after the final\n",
    "# convolutional layer is 7 x 7 x 24. So all 200 nodes receive 1,176\n",
    "# inputs.\n",
    "W4 = tf.Variable(tf.truncated_normal([7 * 7 * c3, f1], stddev=0.1))\n",
    "B4 = tf.Variable(tf.ones([f1])/10)\n",
    "\n",
    "# Now for the softmax (output) layer\n",
    "W5 = tf.Variable(tf.truncated_normal([f1, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.ones([10])/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to build the model! We will perform same padding for each\n",
    "# convolution, reducing dimensions instead by specifying a stride\n",
    "# of two for Conv layers 2 and 3\n",
    "stride = 1  # output is 28x28\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "stride = 2  # output is 14x14\n",
    "Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "stride = 2  # output is 7x7\n",
    "Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "# Flatten the output of the third convolutional layer to go into\n",
    "# the fully connected layer\n",
    "YY = tf.reshape(Y3, shape=[-1, 7 * 7 * c3])\n",
    "\n",
    "# Activation for fully connected layer\n",
    "Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "\n",
    "# softmax layer\n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-d6b6a316fc16>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cost = tf.reduce_mean(cost)\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# prediction of the trained model, for classifying the test set\n",
    "prediction = tf.argmax(Y, 1)\n",
    "\n",
    "# training step, the learning rate is a placeholder\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's initialize and run the session!\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# TODO here I am!\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dev_split=0.2, batch_size=500, learning_rate=0.003, \n",
    "          epochs=1, predict=True):\n",
    "    \n",
    "    training_start = time.time()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Initialize the variables\n",
    "        sess.run(init)\n",
    "        \n",
    "        # number of batches in an epoch\n",
    "        batches = int((len(X_train) * (1-dev_split)) // batch_size)\n",
    "        print(\"Training\", epochs, \"epochs with\", batches, \"batches per epoch.\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            epoch_start = time.time()\n",
    "            epoch_cost = 0\n",
    "            \n",
    "            # split the data into a train and dev set for each epoch\n",
    "            x_train_, x_dev, y_train_, y_dev = train_test_split(X_train, y_train_ohe, test_size=dev_split)\n",
    "            \n",
    "            # run this training data through the neural network\n",
    "            for batch in range(batches):\n",
    "                \n",
    "                # Calculate the start and end indices for the next batch\n",
    "                begin = (batch * batch_size)\n",
    "                end   = (batch * batch_size) + batch_size\n",
    "\n",
    "                # Get the next sequential batch from the training data\n",
    "                batch_xs, batch_ys = x_train_[begin:end], y_train_[begin:end]\n",
    "                \n",
    "                # Feed this batch through the neural network.\n",
    "                _, batch_cost = sess.run([train_step, cost], feed_dict={X: batch_xs, Y_: batch_ys, lr: learning_rate})\n",
    "                # print(batch_cost)\n",
    "                epoch_cost += batch_cost\n",
    "            \n",
    "            # calculate accuracy and print results of epoch\n",
    "            train_accuracy, train_cost = sess.run([accuracy, cost], \n",
    "                                                  {X: x_train_, Y_: y_train_})\n",
    "            dev_accuracy, dev_cost = sess.run([accuracy, cost], \n",
    "                                                {X: x_dev, Y_: y_dev})\n",
    "            epoch_time = round(time.time() - epoch_start, 1)\n",
    "            print(\"Epoch\", epoch+1, \"-\", epoch_time, \"s - train/dev cost:\", \n",
    "                  round(train_cost, 4), \"|\", round(dev_cost, 4), \n",
    "                  \"- train/dev accuracy:\", round(train_accuracy, 4), \n",
    "                  \"|\", round(dev_accuracy, 4))\n",
    "        \n",
    "        # Generate the predictions on the test set\n",
    "        if predict:\n",
    "            predictions = prediction.eval({X: X_test})\n",
    "        \n",
    "    print(\"Total training time:\", round(time.time() - training_start, 1), \"s\")\n",
    "    \n",
    "    # Return the predictions\n",
    "    if predict:\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 epochs with 67 batches per epoch.\n",
      "Epoch 1 - 73.1 s - train/dev cost: 0.17 | 0.1829 - train/dev accuracy: 0.948 | 0.9467\n",
      "Total training time: 97.5 s\n"
     ]
    }
   ],
   "source": [
    "predictions = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good accuracy! Now let's submit our predictions.\n",
    "\n",
    "### Submitting predictions\n",
    "\n",
    "The predictions generated by the model is an array of length 28,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the competition instructions, we need to submit a .csv file in the format of:\n",
    "\n",
    "```\n",
    "ImageId,Label\n",
    "1,0\n",
    "2,0\n",
    "3,0\n",
    "...\n",
    "```\n",
    "\n",
    "To help with this I'll import pandas, create a dataframe with these column headers, and save it to .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageId  Label\n",
       "0         1      2\n",
       "1         2      0\n",
       "2         3      9\n",
       "3         4      9\n",
       "4         5      3\n",
       "5         6      7\n",
       "6         7      0\n",
       "7         8      3\n",
       "8         9      0\n",
       "9        10      3\n",
       "10       11      5\n",
       "11       12      7\n",
       "12       13      4\n",
       "13       14      0\n",
       "14       15      4\n",
       "15       16      3\n",
       "16       17      3\n",
       "17       18      1\n",
       "18       19      9\n",
       "19       20      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_predictions = pd.DataFrame({'ImageId' : np.arange(len(predictions))+1,\n",
    "                               'Label' : predictions})\n",
    "df_predictions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv('tf_cnn_v1_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
