{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iMaterlialist-Keras-ResNet50.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "D5nif5vwTFzx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# iMaterialist Challenge (Furniture) at FGVC5\n",
        "\n",
        "### TFNW Kaggle Team\n",
        "\n",
        "#### Train a ResNet50 network\n",
        "\n",
        "https://www.kaggle.com/c/imaterialist-challenge-furniture-2018\n",
        "\n",
        "@alkari"
      ]
    },
    {
      "metadata": {
        "id": "KXVzUCme6q02",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Restart runtime*"
      ]
    },
    {
      "metadata": {
        "id": "gYX4-r8Xw4ic",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5O4NEmEh48oZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check GPU/Memory"
      ]
    },
    {
      "metadata": {
        "id": "IQ1dj855w_8r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print('Gen RAM Free: ' + humanize.naturalsize( psutil.virtual_memory().available ), ' I Proc size: ' + humanize.naturalsize( process.memory_info().rss))\n",
        " print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZvAiwa05B8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install pre-requisites"
      ]
    },
    {
      "metadata": {
        "id": "-VHyze77Ti22",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install --upgrade -q pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4A8jsDAqW8Ei",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xraYAS_YXr4H",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dv488bkReWg8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yMSDFV8i0EGz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Start here..."
      ]
    },
    {
      "metadata": {
        "id": "XaTljL-87mQT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def elapsed (start):\n",
        "    \"\"\"\n",
        "    Returns elapsed time in hh:mm:ss format from start time in unix format\n",
        "    \"\"\"\n",
        "    elapsed = time.time()-start\n",
        "    hours, rem = divmod(elapsed, 3600)\n",
        "    minutes, seconds = divmod(rem, 60)\n",
        "    return(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhcYvl3_XzuL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bw9S_jGpTF3w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10274cae-ea15-4c07-9d98-86f84fa9b96f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523119067272,
          "user_tz": 420,
          "elapsed": 2311,
          "user": {
            "displayName": "Al Kari",
            "photoUrl": "//lh3.googleusercontent.com/-SzWfWceGuvQ/AAAAAAAAAAI/AAAAAAAAA4M/jdXT3gTXKpM/s50-c-k-no/photo.jpg",
            "userId": "100759185465945066793"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7A_9crFA8Yx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22279005-5e87-4e34-b388-1c0db0e80a15",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523119070525,
          "user_tz": 420,
          "elapsed": 350,
          "user": {
            "displayName": "Al Kari",
            "photoUrl": "//lh3.googleusercontent.com/-SzWfWceGuvQ/AAAAAAAAAAI/AAAAAAAAA4M/jdXT3gTXKpM/s50-c-k-no/photo.jpg",
            "userId": "100759185465945066793"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load Classes\n",
        "\n",
        "test_path=\"iMaterialist/validation_dataset/\"\n",
        "test_dataset_name = 'validation_last'\n",
        "with h5py.File(test_path+'{}_labels.h5'.format(test_dataset_name), 'r') as hf:\n",
        "    test_set_y_orig = np.array(hf['{}_labels'.format(test_dataset_name)][:])\n",
        "\n",
        "classes = []\n",
        "for i in range (1,len(test_set_y_orig)):\n",
        "    if test_set_y_orig[i] not in classes:\n",
        "        classes.append(test_set_y_orig[i])      \n",
        "classes = np.array(classes) # the list of classes\n",
        "print(classes.shape)\n",
        "test_set_y_orig = None"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gj6W-Bl0h2vg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_dataset(train_path, train_dataset_name, batch_size=1000):\n",
        "    #train_path=\"iMaterialist/train_dataset/\"\n",
        "    #test_path=\"iMaterialist/validation_dataset/\"\n",
        "    #train_dataset_name = 'train_1'\n",
        "    #test_dataset_name = 'validation_last'\n",
        "\n",
        "\n",
        "    # Train dataset\n",
        "    with h5py.File(train_path+'{}_images.h5'.format(train_dataset_name), 'r') as hf:\n",
        "        train_set_x_orig = np.array(hf['{}_images'.format(train_dataset_name)][batch_size-1000:batch_size])   \n",
        "    with h5py.File(train_path+'{}_labels.h5'.format(train_dataset_name), 'r') as hf:\n",
        "        train_set_y_orig = np.array(hf['{}_labels'.format(train_dataset_name)][batch_size-1000:batch_size])\n",
        "\n",
        "    # Test dataset (validation)\n",
        "    #with h5py.File(test_path+'{}_images.h5'.format(test_dataset_name), 'r') as hf:\n",
        "    #    test_set_x_orig = np.array(hf['{}_images'.format(test_dataset_name)][batch_size-1000:batch_size])   \n",
        "    #with h5py.File(test_path+'{}_labels.h5'.format(test_dataset_name), 'r') as hf:\n",
        "    #    test_set_y_orig = np.array(hf['{}_labels'.format(test_dataset_name)][batch_size-1000:batch_size])\n",
        "\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    #test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    #return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "    return train_set_x_orig, train_set_y_orig, classes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sn9DEoVrrjOr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16370c07-e396-4782-b74f-c859978a1c1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523115150591,
          "user_tz": 420,
          "elapsed": 2194,
          "user": {
            "displayName": "Al Kari",
            "photoUrl": "//lh3.googleusercontent.com/-SzWfWceGuvQ/AAAAAAAAAAI/AAAAAAAAA4M/jdXT3gTXKpM/s50-c-k-no/photo.jpg",
            "userId": "100759185465945066793"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!free -m"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\r\n",
            "Mem:          13029         529       11840           0         659       12283\r\n",
            "Swap:             0           0           0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wRWG_ap3TF5g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of ResNet identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters= F2, kernel_size= (f,f), strides= (1,1), padding= 'same', name= conv_name_base + '2b', kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis= 3, name= bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters= F3, kernel_size= (1,1), strides= (1,1), padding= 'valid', name= conv_name_base + '2c', kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis= 3, name= bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7be3K_wBTF5n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of ResNet convolutional block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path \n",
        "\n",
        "    X = Conv2D(F2, (f,f), strides= (1,1), padding= 'same', name= conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis= 3, name= bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1,1), strides=(1,1), padding='valid', name= conv_name_base +'2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis= 3, name= bn_name_base +'2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    \n",
        "    X_shortcut = Conv2D(F3, (1,1), strides=(s,s), padding='valid', name= conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut) \n",
        "    X_shortcut = BatchNormalization(axis = 3, name= bn_name_base +'1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvjAbR-LTF7x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape = (300, 300, 3), classes = 129):\n",
        "    \"\"\"\n",
        "    Implementation of ResNet50 with the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJnJLmFETF8h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ]
    },
    {
      "metadata": {
        "id": "B-faWPTnTF8k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = ResNet50(input_shape = (300, 300, 3), classes = 129)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMKd4n2zTF89",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile the model"
      ]
    },
    {
      "metadata": {
        "id": "tNrUvRpKTF9E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0C84BhATGBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model is now ready to be trained. The only thing you need is a dataset."
      ]
    },
    {
      "metadata": {
        "id": "0DBhogvnyFj5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "    train_path=\"iMaterialist/train_dataset/\"\n",
        "    test_path=\"iMaterialist/validation_dataset/\"\n",
        "    #train_dataset_name = 'train_2'\n",
        "    test_dataset_name = 'validation_last'\n",
        "    load_batch_size = 1000\n",
        "    assert load_batch_size == 1000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hN5sRyhuzdMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Begin training"
      ]
    },
    {
      "metadata": {
        "id": "mI7DvPOUTGC1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 13382
        },
        "outputId": "2c907a75-bd53-4a44-9ed1-4d33a489b05d"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "for dataset_number in range (1,10):\n",
        "  train_dataset_name = \"train_{}\".format(dataset_number)\n",
        "  for batch in range(load_batch_size,5001,load_batch_size):\n",
        "    X_train_orig, Y_train_orig, classes = load_dataset(train_path, train_dataset_name, batch)\n",
        "\n",
        "    # Normalize image vectors\n",
        "    X_train = X_train_orig/255.\n",
        "    #X_test = X_test_orig/255.\n",
        "\n",
        "    # Convert training and test labels to one hot matrices\n",
        "    Y_train = convert_to_one_hot(Y_train_orig, 129).T\n",
        "    #Y_test = convert_to_one_hot(Y_test_orig, 129).T\n",
        "\n",
        "    #print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "    #print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "    #print (\"X_train shape: \" + str(X_train.shape))\n",
        "    #print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "    #print (\"X_test shape: \" + str(X_test.shape))\n",
        "    #print (\"Y_test shape: \" + str(Y_test.shape))\n",
        "\n",
        "    print('\\nTraining dataset {}'.format(dataset_number))\n",
        "    print(\"\\n*****Training batch# {}\".format(batch)+\"*****\\n\")\n",
        "    model.fit(X_train, Y_train, epochs = 20, batch_size = 50)\n",
        "    print('\\n-------------------------- Elapsed time: {} --------------------------'.format(elapsed(start)))\n",
        "    model.save('iMaterlialist-Keras-ResNet50-{}.h5'.format(dataset_number))\n",
        "    print('\\nCheckpoint saved. Elapsed time: {}'.format(elapsed(start)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training dataset 1\n",
            "\n",
            "*****Training batch# 1000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 58s 58ms/step - loss: 14.5727 - acc: 0.0110\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 10.7834 - acc: 0.0120\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.2579 - acc: 0.0170\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.2729 - acc: 0.0320\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.4402 - acc: 0.0400\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.9388 - acc: 0.0680\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.5930 - acc: 0.0910\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.5367 - acc: 0.1250\n",
            "Epoch 9/20\n",
            " 850/1000 [========================>.....] - ETA: 7s - loss: 4.2452 - acc: 0.1600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.1806 - acc: 0.1620\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.5994 - acc: 0.2040\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.3879 - acc: 0.2830\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.2707 - acc: 0.2890\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 2.9728 - acc: 0.3440\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 2.7992 - acc: 0.4000\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.6742 - acc: 0.4170\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.5705 - acc: 0.4510\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.2129 - acc: 0.5090\n",
            "Epoch 18/20\n",
            " 500/1000 [==============>...............] - ETA: 24s - loss: 1.9072 - acc: 0.6020"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.9310 - acc: 0.5900\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.0312 - acc: 0.6030\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.9689 - acc: 0.4750\n",
            "\n",
            "Training dataset 1\n",
            "\n",
            "*****Training batch# 2000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.3230 - acc: 0.0510\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.7631 - acc: 0.0750\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.3647 - acc: 0.1200\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.7927 - acc: 0.2040\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.0923 - acc: 0.3260\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.5727 - acc: 0.4520\n",
            "Epoch 7/20\n",
            " 150/1000 [===>..........................] - ETA: 43s - loss: 2.1417 - acc: 0.5733"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.4389 - acc: 0.4890\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 2.0799 - acc: 0.5840\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.6162 - acc: 0.6740\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1495 - acc: 0.7770\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0662 - acc: 0.8220\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8806 - acc: 0.8520\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.7943 - acc: 0.8830\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.7391 - acc: 0.9060\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6238 - acc: 0.9000\n",
            "Epoch 16/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.5829 - acc: 0.9356"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5628 - acc: 0.9350\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.5739 - acc: 0.9260\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5195 - acc: 0.9470\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5422 - acc: 0.9500\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7085 - acc: 0.9110\n",
            "\n",
            "Training dataset 1\n",
            "\n",
            "*****Training batch# 3000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.3604 - acc: 0.0570\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.6827 - acc: 0.0920\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.8324 - acc: 0.1070\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 4.2704 - acc: 0.1720\n",
            "Epoch 5/20\n",
            " 200/1000 [=====>........................] - ETA: 39s - loss: 3.9182 - acc: 0.2400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.6635 - acc: 0.2520\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.7957 - acc: 0.3830\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.3508 - acc: 0.4930\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.9039 - acc: 0.6140\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.4498 - acc: 0.7320\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2283 - acc: 0.7720\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2516 - acc: 0.8160\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8066 - acc: 0.8790\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6930 - acc: 0.9080\n",
            "Epoch 14/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.5950 - acc: 0.9422"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6260 - acc: 0.9400\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7891 - acc: 0.9150\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8740 - acc: 0.8710\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.8863 - acc: 0.6610\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.4378 - acc: 0.7080\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.9634 - acc: 0.8400\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.8715 - acc: 0.6090\n",
            "\n",
            "Training dataset 1\n",
            "\n",
            "*****Training batch# 4000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.9814 - acc: 0.0460\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.6409 - acc: 0.0700\n",
            "Epoch 3/20\n",
            " 300/1000 [========>.....................] - ETA: 35s - loss: 4.3833 - acc: 0.0933"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.4335 - acc: 0.0870\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.1414 - acc: 0.1330\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.8358 - acc: 0.1870\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.7288 - acc: 0.2030\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.2140 - acc: 0.2840\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.7078 - acc: 0.4050\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 2.1342 - acc: 0.5500\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.0369 - acc: 0.3450\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.7769 - acc: 0.4080\n",
            "Epoch 12/20\n",
            " 500/1000 [==============>...............] - ETA: 25s - loss: 1.8510 - acc: 0.6080"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.7210 - acc: 0.6310\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2757 - acc: 0.7480\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.6834 - acc: 0.6440\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0377 - acc: 0.7960\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7081 - acc: 0.9070\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6918 - acc: 0.8940\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6789 - acc: 0.9040\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.5151 - acc: 0.9450\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.4539 - acc: 0.9470\n",
            "\n",
            "Training dataset 1\n",
            "\n",
            "*****Training batch# 5000*****\n",
            "\n",
            "Epoch 1/20\n",
            " 450/1000 [============>.................] - ETA: 26s - loss: 8.1028 - acc: 0.0711"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 6.3945 - acc: 0.0750\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 4.4700 - acc: 0.1130\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 4.0891 - acc: 0.1640\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.7230 - acc: 0.2260\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.2604 - acc: 0.2950\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.4856 - acc: 0.4330\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.6663 - acc: 0.6460\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2496 - acc: 0.7530\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8911 - acc: 0.8560\n",
            "Epoch 10/20\n",
            " 500/1000 [==============>...............] - ETA: 25s - loss: 0.7149 - acc: 0.8780"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7228 - acc: 0.8840\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5317 - acc: 0.9390\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7405 - acc: 0.8790\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7632 - acc: 0.9080\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7981 - acc: 0.8840\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1097 - acc: 0.8250\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.6200 - acc: 0.6590\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 51s 51ms/step - loss: 1.5992 - acc: 0.7760\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0712 - acc: 0.8160\n",
            "Epoch 19/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.6377 - acc: 0.9378"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6468 - acc: 0.9350\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5104 - acc: 0.9540\n",
            "Elapsed time: 01:29:04.84\n",
            "\n",
            "Training dataset 2\n",
            "\n",
            "*****Training batch# 1000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.1025 - acc: 0.0770\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 51s 51ms/step - loss: 4.2217 - acc: 0.1350\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.6364 - acc: 0.2210\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 51s 51ms/step - loss: 2.9466 - acc: 0.3660\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.1227 - acc: 0.5430\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.3132 - acc: 0.7330\n",
            "Epoch 7/20\n",
            " 900/1000 [==========================>...] - ETA: 4s - loss: 1.0065 - acc: 0.8178"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.9975 - acc: 0.8210\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.7750 - acc: 0.8980\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.6417 - acc: 0.9190\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4776 - acc: 0.9510\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4928 - acc: 0.9600\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.5400 - acc: 0.9430\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.5839 - acc: 0.9380\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4570 - acc: 0.9650\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.5029 - acc: 0.9600\n",
            "Epoch 16/20\n",
            " 500/1000 [==============>...............] - ETA: 24s - loss: 0.5426 - acc: 0.9600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4936 - acc: 0.9620\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.5219 - acc: 0.9490\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4981 - acc: 0.9530\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 1.0575 - acc: 0.8360\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 1.3348 - acc: 0.8110\n",
            "\n",
            "Training dataset 2\n",
            "\n",
            "*****Training batch# 2000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 5.7815 - acc: 0.0740\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 4.3338 - acc: 0.1590\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 3.6164 - acc: 0.2130\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 2.8318 - acc: 0.3740\n",
            "Epoch 5/20\n",
            " 250/1000 [======>.......................] - ETA: 36s - loss: 2.4784 - acc: 0.4920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 48s 48ms/step - loss: 2.2716 - acc: 0.5160\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 1.6817 - acc: 0.6890\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 1.0786 - acc: 0.8130\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.9677 - acc: 0.8700\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.6424 - acc: 0.9330\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.6154 - acc: 0.9240\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.6254 - acc: 0.9280\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6960 - acc: 0.9260\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5076 - acc: 0.9570\n",
            "Epoch 14/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.6912 - acc: 0.9467"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7831 - acc: 0.9150\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1865 - acc: 0.8520\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0193 - acc: 0.8520\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 51s 51ms/step - loss: 2.5029 - acc: 0.7820\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.9133 - acc: 0.8530\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1750 - acc: 0.8870\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.9053 - acc: 0.8930\n",
            "\n",
            "Training dataset 2\n",
            "\n",
            "*****Training batch# 3000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.2066 - acc: 0.0720\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 4.3854 - acc: 0.1490\n",
            "Epoch 3/20\n",
            " 300/1000 [========>.....................] - ETA: 35s - loss: 3.5911 - acc: 0.2867"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.6963 - acc: 0.2420\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 2.7616 - acc: 0.4100\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.8363 - acc: 0.6020\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2022 - acc: 0.7730\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8062 - acc: 0.8690\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.3492 - acc: 0.7500\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.9911 - acc: 0.8420\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5405 - acc: 0.9360\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5723 - acc: 0.9410\n",
            "Epoch 12/20\n",
            " 500/1000 [==============>...............] - ETA: 24s - loss: 0.6921 - acc: 0.9140"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6593 - acc: 0.9230\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.5222 - acc: 0.9470\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4365 - acc: 0.9640\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4418 - acc: 0.9580\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4458 - acc: 0.9650\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4503 - acc: 0.9610\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3565 - acc: 0.9750\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3855 - acc: 0.9720\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3864 - acc: 0.9620\n",
            "\n",
            "Training dataset 2\n",
            "\n",
            "*****Training batch# 4000*****\n",
            "\n",
            "Epoch 1/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 8.2243 - acc: 0.0867"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.4160 - acc: 0.0810\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.0658 - acc: 0.1520\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.6258 - acc: 0.2460\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.7160 - acc: 0.3920\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.7764 - acc: 0.6000\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1604 - acc: 0.7690\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8276 - acc: 0.8650\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.6625 - acc: 0.9050\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5006 - acc: 0.9460\n",
            "Epoch 10/20\n",
            " 500/1000 [==============>...............] - ETA: 24s - loss: 0.4248 - acc: 0.9580"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4263 - acc: 0.9520\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3969 - acc: 0.9640\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3678 - acc: 0.9720\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0568 - acc: 0.8490\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.0687 - acc: 0.3740\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.4052 - acc: 0.7710\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.9620 - acc: 0.8580\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.2797 - acc: 0.8790\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0019 - acc: 0.9160\n",
            "Epoch 19/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.8038 - acc: 0.9156"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8343 - acc: 0.9170\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7180 - acc: 0.9140\n",
            "\n",
            "Training dataset 2\n",
            "\n",
            "*****Training batch# 5000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.5566 - acc: 0.0660\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 4.2435 - acc: 0.1610\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.5290 - acc: 0.2670\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.5274 - acc: 0.4490\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.6618 - acc: 0.6450\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0877 - acc: 0.8050\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7215 - acc: 0.9090\n",
            "Epoch 8/20\n",
            " 100/1000 [==>...........................] - ETA: 44s - loss: 0.4122 - acc: 0.9800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5541 - acc: 0.9390\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6261 - acc: 0.9250\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8876 - acc: 0.8710\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6310 - acc: 0.9290\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.5037 - acc: 0.9490\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.5280 - acc: 0.9580\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.5339 - acc: 0.9650\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.4267 - acc: 0.9690\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4185 - acc: 0.9740\n",
            "Epoch 17/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.4302 - acc: 0.9733"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4498 - acc: 0.9660\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3952 - acc: 0.9690\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4936 - acc: 0.9610\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.4065 - acc: 0.9660\n",
            "Elapsed time: 02:56:59.82\n",
            "\n",
            "Training dataset 3\n",
            "\n",
            "*****Training batch# 1000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.0573 - acc: 0.0890\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.9111 - acc: 0.2010\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.1856 - acc: 0.3220\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.3865 - acc: 0.4930\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.4722 - acc: 0.6990\n",
            "Epoch 6/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8941 - acc: 0.8540\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6186 - acc: 0.9190\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4653 - acc: 0.9560\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5749 - acc: 0.9520\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5477 - acc: 0.9510\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.6014 - acc: 0.9250\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5617 - acc: 0.9390\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5385 - acc: 0.9410\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4215 - acc: 0.9690\n",
            "Epoch 15/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.4064 - acc: 0.9667"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3915 - acc: 0.9710\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4752 - acc: 0.9510\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6321 - acc: 0.8990\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4683 - acc: 0.9570\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3925 - acc: 0.9690\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4040 - acc: 0.9720\n",
            "\n",
            "Training dataset 3\n",
            "\n",
            "*****Training batch# 2000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.3201 - acc: 0.0900\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.7923 - acc: 0.2240\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 2.7978 - acc: 0.3970\n",
            "Epoch 4/20\n",
            " 250/1000 [======>.......................] - ETA: 37s - loss: 1.8429 - acc: 0.6400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.8516 - acc: 0.6310\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2625 - acc: 0.7820\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8240 - acc: 0.8890\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6004 - acc: 0.9350\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5936 - acc: 0.9520\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5821 - acc: 0.9520\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5255 - acc: 0.9640\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4784 - acc: 0.9700\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.0314 - acc: 0.8190\n",
            "Epoch 13/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.7757 - acc: 0.8689"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8071 - acc: 0.8610\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5173 - acc: 0.9570\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4797 - acc: 0.9520\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6972 - acc: 0.8740\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.5237 - acc: 0.9460\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4124 - acc: 0.9570\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3734 - acc: 0.9700\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3625 - acc: 0.9700\n",
            "\n",
            "Training dataset 3\n",
            "\n",
            "*****Training batch# 3000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.1630 - acc: 0.1130\n",
            "Epoch 2/20\n",
            " 350/1000 [=========>....................] - ETA: 31s - loss: 3.7683 - acc: 0.2486"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 3.6903 - acc: 0.2330\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.8851 - acc: 0.3790\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.8861 - acc: 0.6200\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1038 - acc: 0.8040\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8552 - acc: 0.8750\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.3687 - acc: 0.7170\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7537 - acc: 0.8680\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4685 - acc: 0.9490\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3460 - acc: 0.9750\n",
            "Epoch 11/20\n",
            " 500/1000 [==============>...............] - ETA: 25s - loss: 0.3121 - acc: 0.9820"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3469 - acc: 0.9790\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3135 - acc: 0.9770\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3364 - acc: 0.9750\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7867 - acc: 0.8680\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.2914 - acc: 0.7690\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4837 - acc: 0.9230\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1716 - acc: 0.9780\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0786 - acc: 0.9910\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0575 - acc: 0.9930\n",
            "Epoch 20/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.0942 - acc: 0.9889"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0648 - acc: 0.9920\n",
            "\n",
            "Training dataset 3\n",
            "\n",
            "*****Training batch# 4000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 6.3339 - acc: 0.1030\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.5130 - acc: 0.2430\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.4182 - acc: 0.4350\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.4467 - acc: 0.6760\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7413 - acc: 0.8260\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3230 - acc: 0.9360\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1213 - acc: 0.9810\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0922 - acc: 0.9840\n",
            "Epoch 9/20\n",
            "  50/1000 [>.............................] - ETA: 45s - loss: 0.0142 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0441 - acc: 0.9950\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0354 - acc: 0.9960\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0538 - acc: 0.9910\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0375 - acc: 0.9920\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0167 - acc: 0.9990\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0211 - acc: 0.9960\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0134 - acc: 0.9980\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0112 - acc: 0.9980\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0105 - acc: 0.9990\n",
            "Epoch 18/20\n",
            " 400/1000 [===========>..................] - ETA: 29s - loss: 0.0160 - acc: 0.9950"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0090 - acc: 0.9980\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0093 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0038 - acc: 1.0000\n",
            "\n",
            "Training dataset 3\n",
            "\n",
            "*****Training batch# 5000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.7414 - acc: 0.1280\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 3.2045 - acc: 0.2860\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.0819 - acc: 0.5060\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 1.0133 - acc: 0.7650\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4256 - acc: 0.9080\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1567 - acc: 0.9680\n",
            "Epoch 7/20\n",
            " 100/1000 [==>...........................] - ETA: 44s - loss: 0.1525 - acc: 0.9700"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0784 - acc: 0.9870\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0796 - acc: 0.9850\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0476 - acc: 0.9920\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0391 - acc: 0.9920\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0143 - acc: 0.9990\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0107 - acc: 0.9990\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0070 - acc: 0.9990\n",
            "Epoch 16/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 0.0092 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0099 - acc: 0.9990\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0043 - acc: 0.9990\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0028 - acc: 1.0000\n",
            "Elapsed time: 04:25:33.73\n",
            "\n",
            "Training dataset 4\n",
            "\n",
            "*****Training batch# 1000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.9694 - acc: 0.1270\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.0353 - acc: 0.3120\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.8301 - acc: 0.5690\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.8138 - acc: 0.8100\n",
            "Epoch 5/20\n",
            " 100/1000 [==>...........................] - ETA: 44s - loss: 0.3467 - acc: 0.9400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2916 - acc: 0.9400\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1032 - acc: 0.9860\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0488 - acc: 0.9930\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0307 - acc: 0.9990\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0218 - acc: 0.9970\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0186 - acc: 0.9980\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0125 - acc: 0.9990\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0175 - acc: 0.9960\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 14/20\n",
            " 450/1000 [============>.................] - ETA: 26s - loss: 0.0048 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0067 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0076 - acc: 0.9990\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0031 - acc: 1.0000\n",
            "\n",
            "Training dataset 4\n",
            "\n",
            "*****Training batch# 2000*****\n",
            "\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 5.6116 - acc: 0.1250\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 3.0012 - acc: 0.3170\n",
            "Epoch 3/20\n",
            " 300/1000 [========>.....................] - ETA: 35s - loss: 1.9705 - acc: 0.5233"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.7910 - acc: 0.5610\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.7493 - acc: 0.8240\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2271 - acc: 0.9590\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0807 - acc: 0.9900\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0495 - acc: 0.9940\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0272 - acc: 0.9960\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0461 - acc: 0.9920\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0159 - acc: 0.9980\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0146 - acc: 0.9980\n",
            "Epoch 12/20\n",
            " 500/1000 [==============>...............] - ETA: 24s - loss: 0.0140 - acc: 0.9960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0116 - acc: 0.9980\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0177 - acc: 0.9980\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0106 - acc: 0.9980\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0111 - acc: 0.9990\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0077 - acc: 0.9980\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0044 - acc: 0.9990\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0101 - acc: 0.9990\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0108 - acc: 0.9980\n",
            "\n",
            "Training dataset 4\n",
            "\n",
            "*****Training batch# 3000*****\n",
            "\n",
            "Epoch 1/20\n",
            " 450/1000 [============>.................] - ETA: 27s - loss: 6.6394 - acc: 0.1289"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 49s 49ms/step - loss: 5.4970 - acc: 0.1290\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 2.9540 - acc: 0.3270\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 1.7252 - acc: 0.5890\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.7442 - acc: 0.8260\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2302 - acc: 0.9580\n",
            "Epoch 6/20\n",
            " 850/1000 [========================>.....] - ETA: 7s - loss: 0.0680 - acc: 0.9906"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iiXjwAs_cp0j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.save('iMaterlialist-Keras-ResNet50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8uAj-XDvQkw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#model.fit(X_train, Y_train, epochs = 20, batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RcoUFz2BTGEh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Try this model on the test set."
      ]
    },
    {
      "metadata": {
        "id": "PH3lW3GwTGFU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = load_model('iMaterlialist-Keras-ResNet50-3.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JF5ymliU4U8Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_test_dataset(test_path, test_dataset_name):\n",
        "\n",
        "    # Test dataset (validation)\n",
        "    with h5py.File(test_path+'{}_images.h5'.format(test_dataset_name), 'r') as hf:\n",
        "        test_set_x_orig = np.array(hf['{}_images'.format(test_dataset_name)][:500])   \n",
        "    with h5py.File(test_path+'{}_labels.h5'.format(test_dataset_name), 'r') as hf:\n",
        "        test_set_y_orig = np.array(hf['{}_labels'.format(test_dataset_name)][:500])\n",
        "\n",
        "    \n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    X_test = test_set_x_orig/255.\n",
        "    Y_test = convert_to_one_hot(test_set_y_orig, 129).T\n",
        "    \n",
        "    return X_test, Y_test\n",
        "\n",
        "\n",
        "test_path=\"iMaterialist/validation_dataset/\"\n",
        "test_dataset_name = 'validation_last'\n",
        "\n",
        "X_test, Y_test = load_test_dataset(test_path, test_dataset_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q25ObD1NTGEt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4f5135c9-3425-4101-fcee-cdca7ceb528d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523119604720,
          "user_tz": 420,
          "elapsed": 453442,
          "user": {
            "displayName": "Al Kari",
            "photoUrl": "//lh3.googleusercontent.com/-SzWfWceGuvQ/AAAAAAAAAAI/AAAAAAAAA4M/jdXT3gTXKpM/s50-c-k-no/photo.jpg",
            "userId": "100759185465945066793"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))\n",
        "print('\\nElapsed time: {}'.format(elapsed(start)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 453s 906ms/step\n",
            "Loss = 8.32625260925293\n",
            "Test Accuracy = 0.10600000002980232\n",
            "\n",
            "Elapsed time: 00:07:32.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "izXwTagjTGLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test on your own image"
      ]
    },
    {
      "metadata": {
        "id": "FZ8NoNMaTGL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can upload an image and see the output of the model. To do this:\n",
        "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\".\n",
        "    2. Add your image to this Jupyter Notebook's directory\n",
        "    3. Write your image's name in the following code\n",
        "    4. Predict! "
      ]
    },
    {
      "metadata": {
        "id": "uCEI2nauTGL9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img_path = 'my_image.jpg'\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "print('Input image shape:', x.shape)\n",
        "my_image = scipy.misc.imread(img_path)\n",
        "imshow(my_image)\n",
        "print(\"class prediction = \")\n",
        "print(model.predict(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XRh-veKbTGMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can also print a summary of your model by running the following code."
      ]
    },
    {
      "metadata": {
        "id": "OY8v6hUITGMb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLaEVsLqTGNE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize this ResNet50. You can also download a .png picture of your model by going to \"File -> Open...-> model.png\"."
      ]
    },
    {
      "metadata": {
        "id": "g0Bk32glTGN1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model.png')\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "syqF_tAgTGQ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### References \n",
        "\n",
        "This notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the github repository of Francois Chollet: \n",
        "\n",
        "- Coursera Convolusional Neural Networks - deeplearning.ai\n",
        "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
        "- Francois Chollet's github repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
      ]
    },
    {
      "metadata": {
        "id": "A394u-7o1U05",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfhbZSH63rfa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! rm -rf /swapfile\n",
        "#!dd if=/dev/zero of=/swapfile bs=1G count=20\n",
        "!fallocate -l 20G /swapfile\n",
        "!chmod 600 /swapfile\n",
        "!ls -lh /swapfile\n",
        "!mkswap /swapfile\n",
        "!swapon /swapfile\n",
        "!sysctl vm.swappiness=10\n",
        "!sysctl vm.vfs_cache_pressure=60\n",
        "!swapon -s\n",
        "!free -m"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}